
#+HUGO_BASE_DIR: ../../
#+HUGO_SECTION: posts

#+TITLE: Personal blog

* Converting openssh private key to PEM format :openssh:
  :PROPERTIES:
  :EXPORT_FILE_NAME: openssh-private-key
  :EXPORT_DATE: 2020-03-29
  :END:
  Newer versions of the =openssh= will use their own format to store a private
  key:

  #+begin_src conf
    -----BEGIN OPENSSH PRIVATE KEY-----
    BASE64KEYTEXT
    -----END OPENSSH PRIVATE KEY-----
  #+end_src
  
  The traditional format of the key can sometimes be useful (or even required -
  for example [[https://guacamole.apache.org/][guacamole]] will not be able to use the =OPENSSH= key format).

  To convert the key use =ssh-keygen=. The command will overwrite the private
  key file, so if the original key should be preserved make sure to create a
  backup:
  
  #+begin_src bash
    ssh-keygen -p -m PEM -f ~/.ssh/id_rsa_test
  #+end_src

  #+name: Output
  #+begin_src conf
    -----BEGIN RSA PRIVATE KEY-----
    BASE64KEYTEXT
    -----END RSA PRIVATE KEY-----
  #+end_src

* Deploying Teamspeak on a Raspberry PI kubernetes cluster :kubernetes:arm:raspberry:
  CLOSED: [2020-05-08 Fri 22:59]
  :PROPERTIES:
  :EXPORT_FILE_NAME: teamspeak-k8s-arm
  :EXPORT_DATE: 2020-04-18
  :END:
  While this post will end up with a running [[https://www.teamspeak.com/en/][Teamspeak]] server, it is very hard
  on the resources of the Raspberry Pi and might not be suitable for everyday
  use.
  
  To deploy a teamspeak server on raspberry pi a few things need to be done:

  - (optional) Get a Kubernetes cluster up and running (this is not required, if
    you just want to run the =docker= container directly).
  - Get Teamspeak to run on =ARM=.
  - Setup an ingress controller to make the Teamspeak server accessible from the
    outside world (in this case this will be the [[https://kubernetes.github.io/ingress-nginx/][Nginx Ingress]]).
** Setting up a kubernetes cluster  
   To setup a kubernetes cluster on Raspberry Pis [[https://k3s.io/][K3S]] is very good approach, as
   the cluster will be more lightweight that simply installing upstream
   kubernetes.

   As a base I recommend using [[https://blog.hypriot.com/][HypriotOS]] or [[https://ubuntu.com/download/server/arm][Ubuntu Server]][fn:3] as those allow
   configuring the images using [[https://cloudinit.readthedocs.io/en/latest/][Cloud-Init]].
   
   Make sure to follow the instructions to use the the =legacy= backend for
   =iptables= if installing =kubernetes= v1.17 or lower: [[https://v1-17.docs.kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#ensure-iptables-tooling-does-not-use-the-nftables-backend][kubeadm instructions]].
   
   When installing =k3s= to run =Teamspeak= =Traefik= should not be installed,
   as only the 2.x version supports =UDP= ingresses - so instead =nginx-ingress=
   will be installed later:

   #+begin_src sh
     curl -sfL https://get.k3s.io | sh -s - --no-deploy=traefik
   #+end_src
** Deploy Teamspeak
*** Build an ARM image for Teamspeak
    Teamspeak does not provide a binary for =ARM=.

    It is however possible to run it using [[https://www.qemu.org/][Qemu]] - I have already prepared an
    =ARM= image that will run the Teamspeak server through =qemu= that you can
    find on my [[https://hub.docker.com/repository/docker/monadt/teamspeak3-server][Dockerhub]] - or if you want to see the source checkout the
    repository on [[https://github.com/bergmannf/teamspeak3-server-arm][Github]].
    
    The image is using the same =entrypoint.sh= as the [[https://hub.docker.com/_/teamspeak][official image]] - so if
    you are already using that one you should be able to use it exactly the same
    way (if not - feel free to open an issue).
*** Deploy the image
    Now - if you do not want to use =kubernetes=, you can simply use the image
    using =docker= and expose the required =Teamspeak= ports as you would with
    =docker=:

    #+begin_src sh
      docker run -p 9987:9987/udp -p 10011:10011 -p 30033:30033 -e TS3SERVER_LICENSE=accept monadt/teamspeak3-server
    #+end_src

    This way is a lot easier on the resources and will likely run more reliable
    on a Raspberry PI with < 2 GB of RAM.
** Setup nginx-ingress 
*** Get nginx-ingress to run on ARM
   Setting up the =nginx-ingress= on a cluster running on =ARM= needs a few extra
   steps when using the [[https://kubernetes.github.io/ingress-nginx/deploy/][official documentation]].
  
   The images used in the =manifests= are not compatible with =armv7= (that is
   used when running a cluster on a bunch of Raspberry Pis).
  
   First the =mandatory.yaml= has to be updated to use the images for the =arm=
   architecture[fn:1]:

   #+begin_src sh
     wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/mandatory.yaml
     sed -i 's/nginx-ingress-controller:0/nginx-ingress-controller-arm:0/' mandatory.yaml
   #+end_src
  
   The resulting =mandatory.yaml= file can now be applied to the cluster:

   #+begin_src sh
     kubectl apply -f mandatory.yaml
   #+end_src
  
   In my local cluster I am using the =NodePort= approach, so the service for
   that can be applied next:
  
   #+begin_src sh
     kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/provider/baremetal/service-nodeport.yaml
   #+end_src
** Setup a Teamspeak deployment
   With all pieces in place the =Teamspeak= container can now be deployed onto
   the cluster:
   
   Save the following =yaml= into a file (e.g. =teamspeak.yaml=).
   #+begin_src yaml
     ---
     apiVersion: v1
     kind: Namespace
     metadata:
       name: teamspeak
     ---
     apiVersion: v1
     kind: PersistentVolumeClaim
     metadata:
       name: teamspeak-pvc
       namespace: teamspeak
     spec:
       accessModes:
         - ReadWriteOnce
       storageClassName: local-path
       resources:
         requests:
           storage: 256Mi
     ---
     apiVersion: apps/v1
     kind: Deployment
     metadata:
       name: teamspeak-deployment
       namespace: teamspeak
       labels:
         app: teamspeak
     spec:
       replicas: 1
       selector:
         matchLabels:
           app: teamspeak
       template:
         metadata:
           namespace: teamspeak
           labels:
             app: teamspeak
         spec:
           containers:
             - name: teamspeak-server
               image: monadt/teamspeak3-server:3.11.0
               ports:
                 - name: ts
                   containerPort: 9987
                   protocol: UDP
               resources:
               env:
               - name: TS3SERVER_LICENSE
                 value: accept
               volumeMounts:
               - mountPath: /var/ts3server/
                 name: teamspeak-data
           volumes:
             - name: teamspeak-data
               persistentVolumeClaim:
                 claimName: teamspeak-pvc
     ---
     apiVersion: v1
     kind: Service
     metadata:
       name: teamspeak-service
       namespace: teamspeak
       labels:
         app: teamspeak
     spec:
       type: ClusterIP
       ports:
         - port: 9987
           targetPort: ts
           protocol: UDP
           name: ts
       selector:
         app: teamspeak
     ---
     apiVersion: v1
     kind: ConfigMap
     metadata:
       name: udp-services
       namespace: ingress-nginx
     data:
       9987: "teamspeak/teamspeak-service:9987"
   #+end_src
    
   Apply this using =kubectl=:

   #+begin_src sh
     kubectl apply -f teamspeak.yaml
   #+end_src
   
   The 9987 =udp= port will also need to be added to the =ingress= service.
   In the =ports= section of the service add the following snippet:

   #+begin_src sh
     kubectl edit svc ingress-nginx -n ingress-nginx
   #+end_src
   
   #+begin_src yaml
       - name: teamspeak
         port: 9987
         protocol: UDP
         targetPort: 9987
   #+end_src

** Forwarding traffic to the ingress
   The final step depends a lot on the setup you are deploying the cluster in.

   If it is behind your local router, you have to check which port was bound to
   the 9987 =udp= port and forward this to one of your cluster-nodes:

   #+begin_src sh
     kubectl describe svc ingress-nginx -n ingress-nginx
   #+end_src
   
   #+begin_src text
     Name:                     ingress-nginx
     Namespace:                ingress-nginx
     Labels:                   app.kubernetes.io/name=ingress-nginx
                               app.kubernetes.io/part-of=ingress-nginx
     Annotations:              Selector:  app.kubernetes.io/name=ingress-nginx,app.kubernetes.io/part-of=ingress-nginx
     Type:                     NodePort
     IP:                       10.43.33.70
     Port:                     http  80/TCP
     TargetPort:               80/TCP
     NodePort:                 http  32224/TCP
     Endpoints:                
     Port:                     https  443/TCP
     TargetPort:               443/TCP
     NodePort:                 https  31955/TCP
     Endpoints:                
     Port:                     teamspeak  9987/UDP
     TargetPort:               9987/UDP
     NodePort:                 teamspeak  31222/UDP
     Endpoints:                
     Session Affinity:         None
     External Traffic Policy:  Cluster
     Events:                   <none>
   #+end_src
   
   In this case the port that needs to be forwarded is the =31222= port (the
   =NodePort= for the 9987 =UDP= port).
* Testing an ansible collection                                     :ansible:
  :PROPERTIES:
  :EXPORT_FILE_NAME: testing-ansible-collections
  :EXPORT_DATE: 2020-05-08
  :END:
  When wanting to work on a collection for =ansible= it is (for now[fn:2]) important
  to check it out in a very specific folder structure or it will not be possible
  to run the tests for it.
  
  When trying to run =ansible-test integration= it will otherwise throw the
  following error:

  #+begin_src text
    ERROR: The current working directory must be at or below:

     - an Ansible collection: {...}/ansible_collections/{namespace}/{collection}/

    Current working directory: <some_other_dir>
  #+end_src

  The collection must be really placed inside a =subfolder= of a folder called
  =ansible_collections= and neither =namespace= nor =collection= can contain
  any symbols except =alphanumberics= or =underscores= (=[a-zA-Z0-9_]=):

  #+begin_src sh
    ansible_collections
    └── namespace
        └── collection
  #+end_src
  
  So if you want to work on an upstream collection (e.g. [[https://github.com/ansible-collections/community.general][community.general]]) you
  should create an intermediate folder =community= and clone the collection into
  the =general= folder (contrary to the default checkout which would be
  =community.general=):
  
  #+begin_src sh
    ansible_collections
    └── community
        └── general
  #+end_src
  
  Inside =general= you can now use run =ansible-test integration= to run
  the integration tests successfully:
  
  #+begin_src sh
    cd ansible_collections/community/general
    poetry init --name community.general --dependency=ansible --dependency=pyyaml --dependency=jinja2 -n
    poetry install
    poetry run ansible-test integration
  #+end_src
* Footnotes

[fn:3] For Ubuntu you will have to edit the file =/boot/firmware/cmdline.txt=
and add the options =cgroup_memory=1 cgroup_enable=memory= at the end of the
line for =k3s= (or =containers= in general) to work.

[fn:2] This might hopefully become easier in the future: https://github.com/ansible/ansible/issues/60215

[fn:1] See https://github.com/kubernetes/ingress-nginx/pull/3852 
